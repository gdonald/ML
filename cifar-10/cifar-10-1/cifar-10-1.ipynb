{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29598a4f",
   "metadata": {},
   "source": [
    "# CIFAR 10 v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7fffd",
   "metadata": {},
   "source": [
    "#### Install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39446d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301dcc88",
   "metadata": {},
   "source": [
    "## Prepare CIFAR-10-C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9e86b",
   "metadata": {},
   "source": [
    "#### Extract CIFAR-10-C.tar archive\n",
    "\n",
    "Delete the CIFAR-10-C and CIFAR-10-C-npy directories if they exist. Extract the CIFAR-10-C.tar file into the current directory. Rename the extracted CIFAR-10-C folder to CIFAR-10-C-npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd676f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted CIFAR-10-C.tar to CIFAR-10-C-npy/\n"
     ]
    }
   ],
   "source": [
    "import tarfile, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "shutil.rmtree(\"CIFAR-10-C\", ignore_errors=True)\n",
    "shutil.rmtree(\"CIFAR-10-C-npy\", ignore_errors=True)\n",
    "\n",
    "filename = \"CIFAR-10-C.tar\"\n",
    "dest = Path(\".\").resolve()\n",
    "\n",
    "with tarfile.open(filename, mode=\"r:*\") as tar:\n",
    "    safe = []\n",
    "    for m in tar.getmembers():\n",
    "        target = (dest / m.name).resolve()\n",
    "        safe.append(m)\n",
    "    tar.extractall(path=dest, members=safe, filter=\"data\")\n",
    "\n",
    "Path(\"CIFAR-10-C\").rename(\"CIFAR-10-C-npy\")\n",
    "\n",
    "print(f\"extracted {filename} to CIFAR-10-C-npy/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85945197",
   "metadata": {},
   "source": [
    "#### Convert Numpy files to images organized by class and severity\n",
    "\n",
    "Scan the CIFAR-10-C-npy directory for all corruption arrays except labels.npy. Load labels.npy and define the class names. For each corruption file, load the array, then for severities 1 through 5 slice the appropriate 10k block of images. Make a severity subfolder like \"s1\" under the folder named after the corruption. Save each image in that slice as a PNG and record a row with the image path and its string label. After processing everything, report how many images were written. Convert the rows into a DataFrame and write CIFAR-10-C-images.csv with path and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48be0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 .npy files in CIFAR-10-C-npy\n",
      "Loaded labels from CIFAR-10-C-npy/labels.npy with shape (50000,)\n",
      "exporting brightness -> CIFAR-10-C/brightness\n",
      "exporting contrast -> CIFAR-10-C/contrast\n",
      "exporting defocus_blur -> CIFAR-10-C/defocus_blur\n",
      "exporting elastic_transform -> CIFAR-10-C/elastic_transform\n",
      "exporting fog -> CIFAR-10-C/fog\n",
      "exporting frost -> CIFAR-10-C/frost\n",
      "exporting gaussian_blur -> CIFAR-10-C/gaussian_blur\n",
      "exporting gaussian_noise -> CIFAR-10-C/gaussian_noise\n",
      "exporting glass_blur -> CIFAR-10-C/glass_blur\n",
      "exporting impulse_noise -> CIFAR-10-C/impulse_noise\n",
      "exporting jpeg_compression -> CIFAR-10-C/jpeg_compression\n",
      "exporting motion_blur -> CIFAR-10-C/motion_blur\n",
      "exporting pixelate -> CIFAR-10-C/pixelate\n",
      "exporting saturate -> CIFAR-10-C/saturate\n",
      "exporting shot_noise -> CIFAR-10-C/shot_noise\n",
      "exporting snow -> CIFAR-10-C/snow\n",
      "exporting spatter -> CIFAR-10-C/spatter\n",
      "exporting speckle_noise -> CIFAR-10-C/speckle_noise\n",
      "exporting zoom_blur -> CIFAR-10-C/zoom_blur\n",
      "Exported 950000 images to CIFAR-10-C\n",
      "Exported CIFAR-10-C-images.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "npy_files_dir_name = \"CIFAR-10-C-npy\"\n",
    "images_dir_name = \"CIFAR-10-C\"\n",
    "\n",
    "npy_dir = Path(npy_files_dir_name)\n",
    "images_dir = Path(images_dir_name)\n",
    "images_dir.mkdir(exist_ok=True)\n",
    "\n",
    "files = sorted([p for p in npy_dir.glob(\"*.npy\") if p.name != \"labels.npy\"])\n",
    "print(f\"Found {len(files)} .npy files in {npy_dir}\")\n",
    "\n",
    "labels_path = npy_dir / \"labels.npy\"\n",
    "labels = np.load(labels_path)\n",
    "print(f\"Loaded labels from {labels_path} with shape {labels.shape}\")\n",
    "\n",
    "CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for p in files:\n",
    "    name = p.stem\n",
    "    print(f\"exporting {name} -> {images_dir / name}\")\n",
    "\n",
    "    X = np.load(p, mmap_mode=\"r\")\n",
    "\n",
    "    for s in range(1, 6):\n",
    "        index_start = 10_000 * (s - 1)\n",
    "        index_end = 10_000 * s\n",
    "\n",
    "        Xs = X[index_start:index_end]\n",
    "        ys = labels[index_start:index_end]\n",
    "\n",
    "        out_dir = images_dir / name / f\"s{s}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for j in range(Xs.shape[0]):\n",
    "            img = Image.fromarray(Xs[j])\n",
    "            image_name = out_dir / f\"{j}.png\"\n",
    "            img.save(image_name, format=\"PNG\")\n",
    "            rows.append({\"path\": str(image_name), \"label\": CLASSES[ys[j]]})\n",
    "\n",
    "print(f\"Exported {len(rows)} images to {images_dir}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"CIFAR-10-C-images.csv\", index=False)\n",
    "print(f\"Exported CIFAR-10-C-images.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127502d",
   "metadata": {},
   "source": [
    "## Prepare CIFAR-10 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a60b7c",
   "metadata": {},
   "source": [
    "#### Extract train.7z archive\n",
    "\n",
    "Delete the CIFAR-10 train directories if they exist. Extract train.7z into the current directory. Rename the extracted train folder to CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5efd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted train.7z to CIFAR-10/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import py7zr\n",
    "\n",
    "shutil.rmtree(\"CIFAR-10\", ignore_errors=True)\n",
    "shutil.rmtree(\"train\", ignore_errors=True)\n",
    "\n",
    "archive = \"train.7z\"\n",
    "\n",
    "with py7zr.SevenZipFile(archive, mode=\"r\") as z:\n",
    "    z.extractall(path='.')\n",
    "\n",
    "Path(\"train\").rename(\"CIFAR-10\")\n",
    "\n",
    "print(f\"extracted {archive} to CIFAR-10/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a10e8",
   "metadata": {},
   "source": [
    "#### Perform train, validate, test split\n",
    "\n",
    "Read trainLabels.csv into a new DataFrame. Create an 80/20 stratified split into train and test. From the train portion, carve out 10 percent for validation, again keeping stratification. Write the three splits to CIFAR-10_train.csv, CIFAR-10_val.csv, and CIFAR-10_test.csv. Print the row counts for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2566ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote CIFAR-10_train.csv 36000\n",
      "wrote CIFAR-10_val.csv 4000\n",
      "wrote CIFAR-10_test.csv 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"trainLabels.csv\")\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"label\"], random_state=17\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=17\n",
    ")\n",
    "\n",
    "train_df.to_csv(\"CIFAR-10_train.csv\", index=False)\n",
    "val_df.to_csv(\"CIFAR-10_val.csv\", index=False)\n",
    "test_df.to_csv(\"CIFAR-10_test.csv\", index=False)\n",
    "\n",
    "print(\"wrote CIFAR-10_train.csv\", len(train_df))\n",
    "print(\"wrote CIFAR-10_val.csv\", len(val_df))\n",
    "print(\"wrote CIFAR-10_test.csv\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f906f72f",
   "metadata": {},
   "source": [
    "## Data summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871d31e",
   "metadata": {},
   "source": [
    "#### CIFAR-10:\n",
    "\n",
    "Load the train, validation, and test CSVs and report their row counts. Compute and display class counts for each splot. Walk the training set images from CIFAR-10/, open each as RGB, and tally image sizes and modes. Accumulate per-channel sums and squared the sums to get totals across all pixels. Compute per-channel mean and standard deviation in the 0 to 1 range from those totals, then print the size and mode tallies and the rounded mean and std values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8ded2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Summary:\n",
      "train rows: 36000\n",
      "val rows: 4000\n",
      "test rows: 10000\n",
      "\n",
      "class counts (train):\n",
      "label\n",
      "airplane      3600\n",
      "automobile    3600\n",
      "bird          3600\n",
      "cat           3600\n",
      "deer          3600\n",
      "dog           3600\n",
      "frog          3600\n",
      "horse         3600\n",
      "ship          3600\n",
      "truck         3600\n",
      "\n",
      "class counts (val):\n",
      "label\n",
      "airplane      400\n",
      "automobile    400\n",
      "bird          400\n",
      "cat           400\n",
      "deer          400\n",
      "dog           400\n",
      "frog          400\n",
      "horse         400\n",
      "ship          400\n",
      "truck         400\n",
      "\n",
      "class counts (test):\n",
      "label\n",
      "airplane      1000\n",
      "automobile    1000\n",
      "bird          1000\n",
      "cat           1000\n",
      "deer          1000\n",
      "dog           1000\n",
      "frog          1000\n",
      "horse         1000\n",
      "ship          1000\n",
      "truck         1000\n",
      "\n",
      "image sizes sample: {(32, 32): 36000}\n",
      "image modes sample: {'RGB': 36000}\n",
      "\n",
      "per-channel mean: [0.490912 0.481628 0.44589 ]\n",
      "per-channel std:  [0.246647 0.243163 0.261323]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "cifar_10_imgs = \"CIFAR-10\"\n",
    "cifar_10_train_csv = \"CIFAR-10_train.csv\"\n",
    "cifar_10_val_csv = \"CIFAR-10_val.csv\"\n",
    "cifar_10_test_csv = \"CIFAR-10_test.csv\"\n",
    "\n",
    "print(\"CIFAR-10 Summary:\")\n",
    "\n",
    "df_train = pd.read_csv(cifar_10_train_csv)\n",
    "print(\"train rows:\", len(df_train))\n",
    "\n",
    "df_val = pd.read_csv(cifar_10_val_csv)\n",
    "print(\"val rows:\", len(df_val))\n",
    "\n",
    "df_test = pd.read_csv(cifar_10_test_csv)\n",
    "print(\"test rows:\", len(df_test))\n",
    "\n",
    "train_counts = df_train[\"label\"].value_counts().sort_index()\n",
    "print(\"\\nclass counts (train):\")\n",
    "print(train_counts.to_string())\n",
    "\n",
    "val_counts = df_val[\"label\"].value_counts().sort_index()\n",
    "print(\"\\nclass counts (val):\")\n",
    "print(val_counts.to_string())\n",
    "\n",
    "test_counts = df_test[\"label\"].value_counts().sort_index()\n",
    "print(\"\\nclass counts (test):\")\n",
    "print(test_counts.to_string())\n",
    "\n",
    "sizes = Counter()\n",
    "modes = Counter()\n",
    "\n",
    "sum_c = np.zeros(3, dtype=np.float64)\n",
    "sum_sq_c = np.zeros(3, dtype=np.float64)\n",
    "pix_count = 0\n",
    "\n",
    "for k, row in df_train.iterrows():\n",
    "    img_path = f\"{cifar_10_imgs}/{row['id']}.png\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    sizes[img.size] += 1\n",
    "    modes[img.mode] += 1\n",
    "\n",
    "    x = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    sum_c += x.sum(axis=(0, 1))\n",
    "    sum_sq_c += (x * x).sum(axis=(0, 1))\n",
    "    pix_count += x.shape[0] * x.shape[1]\n",
    "\n",
    "mean = (sum_c / pix_count).astype(np.float64)\n",
    "var = (sum_sq_c / pix_count) - mean * mean\n",
    "std = np.sqrt(np.clip(var, 0, None))\n",
    "\n",
    "print(\"\\nimage sizes sample:\", dict(sizes))\n",
    "print(\"image modes sample:\", dict(modes))\n",
    "\n",
    "print(\"\\nper-channel mean:\", np.round(mean, 6))\n",
    "print(\"per-channel std: \", np.round(std, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb81ab",
   "metadata": {},
   "source": [
    "#### CIFAR-10-C:\n",
    "\n",
    "Scan the CIFAR-10-C images folder for corruption folders and report their names. For each corruption, walk the severity subfolders s1 through s5, count the PNGs, collect rows of {corruption, severity, count} info, sort them, and print a summary table. Load labels.npy, map label ids to class names, and print overall class counts across all 50k items. Slice labels into five 10k blocks by severity, compute class counts for each block, align them to the class list, concatenate the columns, and print the per severity label table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da85523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10-C Summary:\n",
      "\n",
      "corruptions found: ['brightness', 'contrast', 'defocus_blur', 'elastic_transform', 'fog', 'frost', 'gaussian_blur', 'gaussian_noise', 'glass_blur', 'impulse_noise', 'jpeg_compression', 'motion_blur', 'pixelate', 'saturate', 'shot_noise', 'snow', 'spatter', 'speckle_noise', 'zoom_blur']\n",
      "\n",
      "counts by corruption and severity:\n",
      "       corruption  severity  count\n",
      "       brightness         1  10000\n",
      "       brightness         2  10000\n",
      "       brightness         3  10000\n",
      "       brightness         4  10000\n",
      "       brightness         5  10000\n",
      "         contrast         1  10000\n",
      "         contrast         2  10000\n",
      "         contrast         3  10000\n",
      "         contrast         4  10000\n",
      "         contrast         5  10000\n",
      "     defocus_blur         1  10000\n",
      "     defocus_blur         2  10000\n",
      "     defocus_blur         3  10000\n",
      "     defocus_blur         4  10000\n",
      "     defocus_blur         5  10000\n",
      "elastic_transform         1  10000\n",
      "elastic_transform         2  10000\n",
      "elastic_transform         3  10000\n",
      "elastic_transform         4  10000\n",
      "elastic_transform         5  10000\n",
      "              fog         1  10000\n",
      "              fog         2  10000\n",
      "              fog         3  10000\n",
      "              fog         4  10000\n",
      "              fog         5  10000\n",
      "            frost         1  10000\n",
      "            frost         2  10000\n",
      "            frost         3  10000\n",
      "            frost         4  10000\n",
      "            frost         5  10000\n",
      "    gaussian_blur         1  10000\n",
      "    gaussian_blur         2  10000\n",
      "    gaussian_blur         3  10000\n",
      "    gaussian_blur         4  10000\n",
      "    gaussian_blur         5  10000\n",
      "   gaussian_noise         1  10000\n",
      "   gaussian_noise         2  10000\n",
      "   gaussian_noise         3  10000\n",
      "   gaussian_noise         4  10000\n",
      "   gaussian_noise         5  10000\n",
      "       glass_blur         1  10000\n",
      "       glass_blur         2  10000\n",
      "       glass_blur         3  10000\n",
      "       glass_blur         4  10000\n",
      "       glass_blur         5  10000\n",
      "    impulse_noise         1  10000\n",
      "    impulse_noise         2  10000\n",
      "    impulse_noise         3  10000\n",
      "    impulse_noise         4  10000\n",
      "    impulse_noise         5  10000\n",
      " jpeg_compression         1  10000\n",
      " jpeg_compression         2  10000\n",
      " jpeg_compression         3  10000\n",
      " jpeg_compression         4  10000\n",
      " jpeg_compression         5  10000\n",
      "      motion_blur         1  10000\n",
      "      motion_blur         2  10000\n",
      "      motion_blur         3  10000\n",
      "      motion_blur         4  10000\n",
      "      motion_blur         5  10000\n",
      "         pixelate         1  10000\n",
      "         pixelate         2  10000\n",
      "         pixelate         3  10000\n",
      "         pixelate         4  10000\n",
      "         pixelate         5  10000\n",
      "         saturate         1  10000\n",
      "         saturate         2  10000\n",
      "         saturate         3  10000\n",
      "         saturate         4  10000\n",
      "         saturate         5  10000\n",
      "       shot_noise         1  10000\n",
      "       shot_noise         2  10000\n",
      "       shot_noise         3  10000\n",
      "       shot_noise         4  10000\n",
      "       shot_noise         5  10000\n",
      "             snow         1  10000\n",
      "             snow         2  10000\n",
      "             snow         3  10000\n",
      "             snow         4  10000\n",
      "             snow         5  10000\n",
      "          spatter         1  10000\n",
      "          spatter         2  10000\n",
      "          spatter         3  10000\n",
      "          spatter         4  10000\n",
      "          spatter         5  10000\n",
      "    speckle_noise         1  10000\n",
      "    speckle_noise         2  10000\n",
      "    speckle_noise         3  10000\n",
      "    speckle_noise         4  10000\n",
      "    speckle_noise         5  10000\n",
      "        zoom_blur         1  10000\n",
      "        zoom_blur         2  10000\n",
      "        zoom_blur         3  10000\n",
      "        zoom_blur         4  10000\n",
      "        zoom_blur         5  10000\n",
      "\n",
      "label counts from labels.npy (all severities combined):\n",
      "airplane      5000\n",
      "automobile    5000\n",
      "bird          5000\n",
      "cat           5000\n",
      "deer          5000\n",
      "dog           5000\n",
      "frog          5000\n",
      "horse         5000\n",
      "ship          5000\n",
      "truck         5000\n",
      "\n",
      "label counts per severity (from labels.npy):\n",
      "              s1    s2    s3    s4    s5\n",
      "airplane    1000  1000  1000  1000  1000\n",
      "automobile  1000  1000  1000  1000  1000\n",
      "bird        1000  1000  1000  1000  1000\n",
      "cat         1000  1000  1000  1000  1000\n",
      "deer        1000  1000  1000  1000  1000\n",
      "dog         1000  1000  1000  1000  1000\n",
      "frog        1000  1000  1000  1000  1000\n",
      "horse       1000  1000  1000  1000  1000\n",
      "ship        1000  1000  1000  1000  1000\n",
      "truck       1000  1000  1000  1000  1000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cifar_10_c_imgs = \"CIFAR-10-C\"\n",
    "cifar_10_c_labels = \"CIFAR-10-C-npy/labels.npy\"\n",
    "\n",
    "print(\"CIFAR-10-C Summary:\\n\")\n",
    "\n",
    "corruptions = sorted([p for p in Path(cifar_10_c_imgs).iterdir() if p.is_dir()])\n",
    "print(\"corruptions found:\", [c.name for c in corruptions])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for corruption_dir in corruptions:\n",
    "    for severity_dir in sorted(corruption_dir.glob(\"s*\")):       \n",
    "        count = sum(1 for _ in severity_dir.glob(\"*.png\"))\n",
    "        \n",
    "        rows.append(\n",
    "            {\n",
    "                \"corruption\": corruption_dir.name,\n",
    "                \"severity\": int(severity_dir.name[1:]),\n",
    "                \"count\": count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "c10c_df = pd.DataFrame(rows).sort_values([\"corruption\", \"severity\"])\n",
    "\n",
    "print(\"\\ncounts by corruption and severity:\")\n",
    "print(c10c_df.to_string(index=False))\n",
    "\n",
    "labels = np.load(cifar_10_c_labels)\n",
    "\n",
    "CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "overall = (\n",
    "    pd.Series(labels)\n",
    "    .map(lambda i: CLASSES[int(i)])\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")\n",
    "print(\"\\nlabel counts from labels.npy (all severities combined):\")\n",
    "print(overall.to_string())\n",
    "\n",
    "per_sev = []\n",
    "\n",
    "for s in range(1, 6):\n",
    "    i0, i1 = 10_000 * (s - 1), 10_000 * s\n",
    "    \n",
    "    sev_counts = (\n",
    "        pd.Series(labels[i0:i1])\n",
    "        .map(lambda i: CLASSES[int(i)])\n",
    "        .value_counts()\n",
    "    )\n",
    "    sev_counts = sev_counts.reindex(CLASSES, fill_value=0)\n",
    "    per_sev.append(sev_counts.rename(f\"s{s}\"))\n",
    "\n",
    "per_sev_df = pd.concat(per_sev, axis=1)\n",
    "print(\"\\nlabel counts per severity (from labels.npy):\")\n",
    "print(per_sev_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
